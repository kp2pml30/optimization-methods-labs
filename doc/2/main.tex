\documentclass[russian, english]{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{csvsimple}
\usepackage{hyperref}
\usepackage[pdf]{graphviz}
\usepackage[final]{pdfpages}

\inputencoding{utf8}
\def\code#1{\texttt{#1}}

\begin{document}

\begin{titlepage}
\centering
	{\scshape\LARGE Методы оптимизации \par}
	\vspace{1cm}
	{\scshape\Large Лабораторная работа №2\par}
	\vspace{2cm}
	{\Large\itshape Дмитрий Проценко M3234 \par
	Кирилл Прокопенко M3236 \par
	Николай Холявин M3238 \par}
	\vfill
	ИТМО y2019
	\vfill
	{\large \today\par}
\end{titlepage}

\tableofcontents
\newpage

\section{Цель}
Исследовать методы:
\begin{itemize}
	\item градиентного спуска
	\item наискорейшего спуска
	\item сопряженных градиентов
\end{itemize}

TODO

\section{Примеры квадратичных функций}
\noindent\makebox[\textwidth]{\includegraphics[width=\paperwidth]{1.png}}
Видно, что все методы, стартуя из одной точки, идут в одном направлении (антиградиента). Метод градиентного спуска каждый раз ``перепрыгивает'' минимум по направлению, поскольку его фиксированный шаг больше. Метод сопряженных градиентов находит минимум в 2 шага, поскольку это верхняя граница числа его итераций --- размерность пространства. Метод наискорейшего спуска каждый раз находит минимум по направлению, что видно на картинке.
\section{Зависимость числа итераций}
\subsection{Параметры}
\csvautotabular[separator=tab]{properties.tsv}
\subsection{Графики}
\def\makePlots#1#2{
	\subsubsection{#2}
	\pgfplotstableread{#1}{\ratiosCsv}
	\begin{tikzpicture}[trim axis left]
		\begin{axis}[
			scale only axis,
			width=\textwidth,
			legend style={at={(0.5,-0.2)},anchor=north},
			xlabel = {число обусловленности},
			ylabel = {итерация},
		]
			\foreach \ind in {10, 100, 1000, 10000}{
				\edef\temp{\noexpand\addlegendentry{$n=\ind$}}
				\addplot table [x={cond}, y={n=\ind}] {\ratiosCsv};
				\temp
			}
		\end{axis}
	\end{tikzpicture}
}

``Шумные'' падения на графиках свзяаны с тем, что иногда может ``повезти'' и антиградиент приблизит к минимуму сильнее, чем в среднем.

\newpage
\makePlots{gradient-descent.tsv}{Градиентный спуск}
Визуально идет скачками с удвоением.
\newpage
\makePlots{steepest-descent.tsv}{Наискорейший спуск}
Демонстрируется ``линейная сходимость''.
\newpage
\makePlots{conjugate-gradient-descent.tsv}{Метод сопряженных градиентов}
Изученная теоеория утверждает, что сходится не более чем за константное число шагов для квадратичных функций (равное $n$), что подтвердилось экспериментами (для $n=10$)

\newpage
\section{Вывод}
В ходе работы была реализована библиотека методов многомерной оптимизации на основе кода прошлой лабораторной работы, разработан пользовательский интерфейс, исследована зависимость числа итераций от размерности пространства и числа обусловленности. Полученные результаты были обоснованы на основании изученной теории. \\
Метод сопряженных градиентов имеет меньшее число итераций, чем другие методы.

\appendix
\section{Код}
Основано на первой лабораторной, исправлены некоторые архитекнутрные недостатки.

\section{Диаграмма классов}
Из-за использования концептов doxygen не сгенерирует адекватную диаграмму.
%\setboolean{@twoside}{false}
\includepdf[pages=-,pagecommand={},width=\paperwidth]{project.pdf}

\section{FAQ}
\def\Question#1#2{
	\item\begin{itemize}
		\item[В] #1
		\item[О] #2
	\end{itemize}
}
\begin{itemize}
	\Question{Чему равны градиент и гессиан квадратичной функции?}{$(\frac{1}{2}Ax^2+bx+c=0)' = Ax + b$\\ $(Ax + b)' = A$}
	\Question{Каким свойством обладает квадратичная функция с положительно определенной матрицей A?}{Имеет глобальный минимум, выпуклая}
	\Question{Чем можете охарактеризовать собственный вектор матрицы $А$ квадратичной функции?}{Собственным числом!!!}
	\Question{Когда говорят, что в итерационном процессе производится исчерпывающий спуск?}{Спуск до миниума по направлению (решение одномерной оптимизации)}
	\Question{Какие направления дифференцируемой в точке функции называются направлениями убывания? Каков геометрический смысл направления убывания?}{Точка $S$, направление $D$. Существует окрестность в которой функция меньше, т.е. $\exists E > 0: \forall\varepsilon \le E: f(S+D\cdot\varepsilon)\le f(S)$}
	\Question{Какова скорость сходимости метода градиентного спуска для квадратичной функции с положительно определенной симметричной матрицей $A$, где $l$ и $L$ -- ее наименьшее и наибольшее собственные значения?}{}
	\Question{Когда говорят, что сильно выпуклая функция имеет овражный характер? Какие задачи минимизации называются хорошо обусловленными, а какие -- плохо обусловленными?}{}
	\Question{В чем состоят преимущества и недостатки метода наискорейшего спуска по сравнению с методом градиентного спуска?}{Идет в "идеальную" точку по направлению, не перескочит минимум, но нужна одномерная оптимизация, которая много раз будет вычислять изначальную функцию, что может быть недопустимо.}
	\Question{Каков главный недостаток градиентных методов?}{Находят локальный минимум, требуют производную}
	\Question{В чем состоит идея метода сопряженных градиентов? Чем этот метод отличается от методов градиентного и наискорейшего спуска?}{Изначально рассчитан на квадратичные функций, но обощается}
\end{itemize}

\end{document}
